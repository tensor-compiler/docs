<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="favicon.ico" />
    <title>Defining Tensors - TACO Documentation</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Defining Tensors";
        var mkdocs_page_input_path = "pytensors.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> TACO Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">C++ API</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="tensors.html">Defining Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="computations.html">Computing on Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="scheduling.html">Providing a Schedule</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Python API</span></p>
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" href="pytensors.html">Defining Tensors</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#declaring-tensors">Declaring Tensors</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#defining-tensor-formats">Defining Tensor Formats</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#initializing-tensors">Initializing Tensors</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#file-io">File I/O</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#numpy-and-scipy-io">NumPy and SciPy I/O</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="pycomputations.html">Computing on Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="http://tensor-compiler.org/reference/">Reference Manual</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Example Applications</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="scientific_computing.html">Scientific Computing: SpMV</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="data_analytics.html">Data Analytics: MTTKRP</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="machine_learning.html">Machine Learning: SDDMM</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Advanced Usage</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="optimization.html">Strategies for Optimization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Guide to Benchmarking</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="controlling_memory.html">Controlling Memory</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">TACO Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Python API &raquo;</li>
      <li>Defining Tensors</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="defining-tensors">Defining Tensors</h1>
<h2 id="declaring-tensors">Declaring Tensors</h2>
<p><code>pytaco.tensor</code> objects, which represent mathematical tensors, form the core of
the TACO Python library. You can can declare a new tensor by specifying the
sizes of each dimension, the <a href="pytensors.html#defining-tensor-formats">format</a>
that will be used to store the tensor, and the
<a href="http://tensor-compiler.org/reference/rst_files/dtype_object.html">datatype</a> of the tensor's nonzero
elements:</p>
<pre class="highlight"><code class="language-python"># Import the TACO Python library
import pytaco as pt
from pytaco import dense, compressed

# Declare a new tensor of double-precision floats with dimensions 
# 512 x 64 x 2048, stored as a dense-sparse-sparse tensor
A = pt.tensor([512, 64, 2048], pt.format([dense, compressed, compressed]), pt.float64)</code></pre>
<p>The datatype can be omitted, in which case TACO will default to using
<code>pt.float32</code> to store the tensor's nonzero elements:</p>
<pre class="highlight"><code class="language-python"># Declare the same tensor as before
A = pt.tensor([512, 64, 2048], pt.format([dense, compressed, compressed]))</code></pre>
<p>Instead of specifying a format that is tied to the number of dimensions that a
tensor has, we can simply specify whether all dimensions are dense or sparse:</p>
<pre class="highlight"><code class="language-python"># Declare a tensor where all dimensions are dense
A = pt.tensor([512, 64, 2048], dense)

# Declare a tensor where all dimensions are sparse
B = pt.tensor([512, 64, 2048], compressed)</code></pre>
<p>Scalars, which correspond to tensors that have zero dimension, can be declared
and initialized with an arbitrary value as demonstrated below:</p>
<pre class="highlight"><code class="language-python"># Declare a scalar
aplha = pt.tensor(42.0)</code></pre>
<h2 id="defining-tensor-formats">Defining Tensor Formats</h2>
<p>Conceptually, you can think of a tensor as a tree where each level (excluding
the root) corresponding to a dimension of the tensor.  Each path from the root
to a leaf node represents the coordinates of a tensor element and its
corresponding value.  Which dimension of the tensor each level of the tree
corresponds to is determined by the order in which tensor dimensions are
stored.</p>
<p>TACO uses a novel scheme that can describe different storage formats for a
tensor by specifying the order in which tensor dimensions are stored and
whether each dimension is sparse or dense.  A sparse (compressed) dimension
stores only the subset of the dimension that contains non-zero values, using
index arrays that are found in the compressed sparse row (CSR) matrix format.
A dense dimension, on the other hand, conceptually stores both zeros and
non-zeros.  This scheme is flexibile enough to express many commonly-used
tensor storage formats:</p>
<pre class="highlight"><code class="language-python">import pytaco as pt
from pytaco import dense, compressed

dm   = pt.format([dense, dense])                        # (Row-major) dense matrix format
csr  = pt.format([dense, compressed])                   # Compressed sparse row matrix format
csc  = pt.format([dense, compressed], [1, 0])           # Compressed sparse column matrix format
dcsc = pt.format([compressed, compressed], [1, 0])      # Doubly compressed sparse column matrix format
csf  = pt.format([compressed, compressed, compressed])  # Compressed sparse fiber tensor format</code></pre>
<p>As demonstrated above, you can define a new tensor storage format by creating a
<code>pytaco.format</code> object.  This requires specifying whether each tensor dimension
is dense or sparse as well as (optionally) the order in which dimensions should
be stored.  TACO also predefines some common tensor formats (including 
<code>pt.csr</code> and <code>pt.csc</code>) that you can use out of the box.</p>
<h2 id="initializing-tensors">Initializing Tensors</h2>
<p>Tensors can be made by using python indexing syntax. For example, one may write
the following: You can initialize a tensor by calling its <code>insert</code> method to
add a nonzero element to the tensor. The <code>insert</code> method takes two arguments:
a list specifying the coordinates of the nonzero element to be added and the
value to be inserted at that coordinate:</p>
<pre class="highlight"><code class="language-python"># Declare a sparse tensor
A = pt.tensor([512, 64, 2048], compressed)

# Set A(0, 1, 0) = 42.0
A.insert([0, 1, 0], 42.0)</code></pre>
<p>If multiple elements are inserted at the same coordinates, they are summed 
together:</p>
<pre class="highlight"><code class="language-python"># Declare a sparse tensor
A = pt.tensor([512, 64, 2048], compressed)

# Set A(0, 1, 0) = 42.0 + 24.0 = 66.0
A.insert([0, 1, 0], 42.0)
A.insert([0, 1, 0], 24.0)</code></pre>
<p>The <code>insert</code> method adds the inserted nonzero element to a temporary buffer.
Before a tensor can actually be used in a computation though, the <code>pack</code> method
must be invoked to pack the tensor into the storage format that was specified
when the tensor was first declared.  TACO will automatically do this
immediately before the tensor is used in a computation.  You can also manually
invoke <code>pack</code> though if you need full control over when exactly that is done:</p>
<pre class="highlight"><code class="language-python">A.pack()</code></pre>
<p>You can then iterate over the nonzero elements of the tensor as follows:</p>
<pre class="highlight"><code class="language-python">for coordinates, val in A:
  print(val)</code></pre>
<h2 id="file-io">File I/O</h2>
<p>Rather than manually constructing a tensor, you can load tensors directly from
file by invoking the <code>pytaco.read</code> function:</p>
<pre class="highlight"><code class="language-python"># Load a dense-sparse-sparse tensor from file "A.tns"
A = pt.read("A.tns", pt.format([dense, compressed, compressed]))</code></pre>
<p>By default, <code>pytaco.read</code> returns a tensor that has already been packed into
the specified storage format. You can optionally pass a Boolean flag as an
argument to indicate whether the returned tensor should be packed or not: </p>
<pre class="highlight"><code class="language-python"># Load an unpacked tensor from file "A.tns"
A = pt.read("A.tns", format([dense, compressed, compressed]), false)</code></pre>
<p>The loaded tensor will then remain unpacked until the <code>pack</code> method is manually 
invoked or a computation that uses the tensor is performed.</p>
<p>You can also write a tensor directly to file by invoking the <code>pytaco.write</code>
function:</p>
<pre class="highlight"><code class="language-python"># Write tensor A to file "A.tns"
pt.write("A.tns", A)</code></pre>
<p>TACO supports loading tensors from and storing tensors to the following file
formats:</p>
<ul>
<li><a href="http://math.nist.gov/MatrixMarket/formats.html#MMformat">Matrix Market (Coordinate) Format (.mtx)</a></li>
<li><a href="https://www.cise.ufl.edu/research/sparse/matrices/DOC/rb.pdf">Rutherford-Boeing Format (.rb)</a></li>
<li><a href="http://frostt.io/tensors/file-formats.html">FROSTT Format (.tns)</a></li>
</ul>
<h2 id="numpy-and-scipy-io">NumPy and SciPy I/O</h2>
<p>Tensors can also be initialized with either NumPy arrays or SciPy sparse (CSR 
or CSC) matrices:</p>
<pre class="highlight"><code class="language-python">import pytaco as pt
import numpy as np
import scipy.sparse

# Assuming SciPy matrix is stored in CSR
sparse_matrix = scipy.sparse.load_npz('sparse_matrix.npz')

# Cast the matrix as a TACO tensor (also stored in CSR)
taco_tensor = pt.from_sp_csr(sparse_matrix)

# We can also load a NumPy array
np_array = np.load('arr.npy')

# And initialize a TACO tensor from this array
dense_tensor = pt.from_array(np_array)</code></pre>
<p>We can also export TACO tensors to either NumPy arrays or SciPy sparse
matrices:</p>
<pre class="highlight"><code class="language-python"># Convert the tensor to a SciPy CSR matrix
sparse_matrix = taco_tensor.to_sp_csr()

# Convert the tensor to a NumPy array
np_array = dense_tensor.to_array()</code></pre>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="scheduling.html" class="btn btn-neutral float-left" title="Providing a Schedule"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="pycomputations.html" class="btn btn-neutral float-right" title="Computing on Tensors">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="scheduling.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="pycomputations.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '.';</script>
    <script src="js/theme_extra.js" defer></script>
    <script src="js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
