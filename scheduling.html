<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="favicon.ico" />
    <title>Providing a Schedule - TACO Documentation</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Providing a Schedule";
        var mkdocs_page_input_path = "scheduling.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> TACO Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">C++ API</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="tensors.html">Defining Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="computations.html">Computing on Tensors</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="scheduling.html">Providing a Schedule</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#pos-command">Pos Command</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#fuse-command">Fuse Command</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#split-command">Split Command</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#precompute-command">Precompute Command</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#reorder-command">Reorder Command</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#bound-command">Bound Command</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#unroll-command">Unroll Command</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#parallelize-command">Parallelize Command</a>
    </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Python API</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="pytensors.html">Defining Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="pycomputations.html">Computing on Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="http://tensor-compiler.org/reference/">Reference Manual</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Example Applications</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="scientific_computing.html">Scientific Computing: SpMV</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="data_analytics.html">Data Analytics: MTTKRP</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="machine_learning.html">Machine Learning: SDDMM</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Advanced Usage</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="optimization.html">Strategies for Optimization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Guide to Benchmarking</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="controlling_memory.html">Controlling Memory</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">TACO Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>C++ API &raquo;</li>
      <li>Providing a Schedule</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="providing-a-schedule">Providing a Schedule</h1>
<p>The scheduling language enables users to specify and compose transformations to
further optimize the code generated by TACO. </p>
<p>Consider the following SpMV computation and associated code, which we will
transform below:
<pre class="highlight"><code class="language-c++">Format csr({Dense,Sparse});
Tensor&lt;double&gt; A("A", {512, 64}, csr);
Tensor&lt;double&gt; x("x", {64}, {Dense});
Tensor&lt;double&gt; y("y", {512}, {Dense});

IndexVar i("i"), j("j"); 
Access matrix = A(i, j);
y(i) = matrix * x(j);
IndexStmt stmt = y.getAssignment().concretize();</code></pre>
<pre class="highlight"><code class="language-c">for (int32_t i = 0; i &lt; A1_dimension; i++) {
    for (int32_t jA = A2_pos[i]; jA &lt; A2_pos[(i + 1)]; jA++) {
        int32_t j = A2_crd[jA];
        y_vals[i] = y_vals[i] + A_vals[jA] * x_vals[j];
    }
}</code></pre></p>
<h2 id="pos-command">Pos Command</h2>
<p>The <code>pos(i, ipos, access)</code> transformation takes in an index variable <code>i</code> that
iterates over the coordinate space of <code>access</code> and replaces it with a derived
index variable <code>ipos</code> that iterates over the same iteration range, but with
respect to the the position space. </p>
<p>Since the <code>pos</code> transformation is not valid for dense level formats, for the
SpMV example, the following would result in an error:
<pre class="highlight"><code class="language-c++">stmt = stmt.pos(i, IndexVar("ipos"), matrix);</code></pre></p>
<p>We could instead have: 
<pre class="highlight"><code class="language-c++">stmt = stmt.pos(j, IndexVar("jpos"), matrix);</code></pre>
<pre class="highlight"><code class="language-c">for (int32_t i = 0; i &lt; A1_dimension; i++) {
    for (int32_t jposA = A2_pos[i]; jposA &lt; A2_pos[(i + 1)]; jposA++) {
        if (jposA &lt; A2_pos[i] || jposA &gt;= A2_pos[(i + 1)])
            continue;

        int32_t j = A2_crd[jposA];
        y_vals[i] = y_vals[i] + A_vals[jposA] * x_vals[j];
    }
} </code></pre></p>
<h2 id="fuse-command">Fuse Command</h2>
<p>The <code>fuse(i, j, f)</code> transformation takes in two index variables <code>i</code> and <code>j</code>,
where <code>j</code> is directly nested under <code>i</code>, and collapses them into a fused index
variable <code>f</code> that iterates over the product of the coordinates <code>i</code> and <code>j</code>. </p>
<p><code>fuse</code> helps facilitate other transformations, such as iterating over the
position space of several index variables, as in this SpMV example: 
<pre class="highlight"><code class="language-c++">IndexVar f("f");
stmt = stmt.fuse(i, j, f);
stmt = stmt.pos(f, IndexVar("fpos"), matrix);</code></pre>
<pre class="highlight"><code class="language-c">for (int32_t fposA = 0; fposA &lt; A2_pos[A1_dimension]; fposA++) {
    if (fposA &gt;= A2_pos[A1_dimension])
        continue;

    int32_t f = A2_crd[fposA];
    while (fposA == A2_pos[(i_pos + 1)]) {
        i_pos++;
        i = i_pos;
    }
    y_vals[i] = y_vals[i] + A_vals[fposA] * x_vals[f];
}</code></pre></p>
<h2 id="split-command">Split Command</h2>
<p>The <code>split(i, i0, i1, splitFactor)</code> transformation splits (strip-mines) an
index variable <code>i</code> into two nested index variables <code>i0</code> and <code>i1</code>. The size of
the inner index variable <code>i1</code> is then held constant at <code>splitFactor</code>, which
must be a positive integer.</p>
<p>For the SpMV example, we could have: 
<pre class="highlight"><code class="language-c++">stmt = stmt.split(i, IndexVar("i0"), IndexVar("i1"), 16);</code></pre>
<pre class="highlight"><code class="language-c">for (int32_t i0 = 0; i0 &lt; ((A1_dimension + 15) / 16); i0++) {
    for (int32_t i1 = 0; i1 &lt; 16; i1++) {
        int32_t i = i0 * 16 + i1;
        if (i &gt;= A1_dimension)
            continue;

        for (int32_t jA = A2_pos[i]; jA &lt; A2_pos[(i + 1)]; jA++) {
            int32_t j = A2_crd[jA];
            y_vals[i] = y_vals[i] + A_vals[jA] * x_vals[j];
        }
    }
}</code></pre></p>
<!-- (not yet implemented) -->
<!-- ## Divide Command

The `divide(i, i0, i1, divideFactor)` transformation divides an index variable
`i` into two nested index variables `i0` and `i1`. The size of the outer index
variable `i0` is then held constant at `divideFactor`, which must be a positive
integer.  -->

<h2 id="precompute-command">Precompute Command</h2>
<p>The <code>precompute(expr, i, iw, workspace)</code> transformation, which is described in
more detail <a href="http://tensor-compiler.org/taco-workspaces.pdf">here</a>, leverages
scratchpad memories and reorders computations to increase cache locality. </p>
<p>Given a subexpression <code>expr</code> to precompute, an index variable <code>i</code> to precompute
over, and an index variable <code>iw</code> (which can be the same or different as <code>i</code>) to
precompute with, the precomputed results are stored in the tensor variable
<code>workspace</code>. </p>
<p>For the SpMV example, if <code>rhs</code> is the right hand side of the original
statement, we could have: 
<pre class="highlight"><code class="language-c++">TensorVar workspace("workspace", Type(Float64, {Dimension(64)}), taco::dense);
stmt = stmt.precompute(rhs, j, j, workspace);</code></pre>
<pre class="highlight"><code class="language-c">for (int32_t i = 0; i &lt; A1_dimension; i++) {
    double* restrict workspace = 0;
    workspace = (double*)malloc(sizeof(double) * 64);
    for (int32_t pworkspace = 0; pworkspace &lt; 64; pworkspace++) {
        workspace[pworkspace] = 0.0;
    }
    for (int32_t jA = A2_pos[i]; jA &lt; A2_pos[(i + 1)]; jA++) {
        int32_t j = A2_crd[jA];
        workspace[j] = A_vals[jA] * x_vals[j];
    }
    for (int32_t j = 0; j &lt; 64; j++) {
        y_vals[i] = y_vals[i] + workspace[j];
    }
    free(workspace);
  }</code></pre></p>
<h2 id="reorder-command">Reorder Command</h2>
<p>The <code>reorder(vars)</code> transformation takes in a new ordering for a set of index
variables in the expression that are directly nested in the iteration order. </p>
<p>For the SpMV example, we could have: 
<pre class="highlight"><code class="language-c++">stmt = stmt.reorder({j, i});</code></pre>
<pre class="highlight"><code class="language-c">for (int32_t jA = A2_pos[iA]; jA &lt; A2_pos[(iA + 1)]; jA++) {
    int32_t j = A2_crd[jA];
    for (int32_t i = 0; i &lt; A1_dimension; i++) {
        y_vals[i] = y_vals[i] + A_vals[jA] * x_vals[j];
    }
 }</code></pre></p>
<h2 id="bound-command">Bound Command</h2>
<p>The <code>bound(i, ibound, bound, bound_type)</code> transformation replaces an index
variable <code>i</code> with an index variable <code>ibound</code> that obeys a compile-time
constraint on its iteration space, incorporating knowledge about the size or
structured sparsity pattern of the corresponding input. The meaning of <code>bound</code>
depends on the <code>bound_type</code>.</p>
<p>For the SpMV example, we could have
<pre class="highlight"><code class="language-c++">stmt = stmt.bound(i, IndexVar("ibound"), 100, BoundType::MaxExact); </code></pre>
<pre class="highlight"><code class="language-c">for (int32_t ibound = 0; ibound &lt; 100; ibound++) {
    for (int32_t jA = A2_pos[ibound]; jA &lt; A2_pos[(ibound + 1)]; jA++) {
        int32_t j = A2_crd[jA];
        y_vals[ibound] = y_vals[ibound] + A_vals[jA] * x_vals[j];
    }
}</code></pre></p>
<h2 id="unroll-command">Unroll Command</h2>
<p>The <code>unroll(i, unrollFactor)</code> transformation unrolls the loop corresponding to
an index variable <code>i</code> by <code>unrollFactor</code> number of iterations, where
<code>unrollFactor</code> is a positive integer. </p>
<p>For the SpMV example, we could have
<pre class="highlight"><code class="language-c++">stmt = stmt.split(i, i0, i1, 32);
stmt = stmt.unroll(i0, 4);</code></pre>
<pre class="highlight"><code class="language-c">if ((((A1_dimension + 31) / 32) * 32 + 32) + (((A1_dimension + 31) / 32) * 32 + 32) &gt;= A1_dimension) {
    for (int32_t i0 = 0; i0 &lt; ((A1_dimension + 31) / 32); i0++) {
        for (int32_t i1 = 0; i1 &lt; 32; i1++) {
            int32_t i = i0 * 32 + i1;
            if (i &gt;= A1_dimension)
                continue;

            for (int32_t jA = A2_pos[i]; jA &lt; A2_pos[(i + 1)]; jA++) {
                int32_t j = A2_crd[jA];
                y_vals[i] = y_vals[i] + A_vals[jA] * x_vals[j];
            }
        }
    }
}
else {
    #pragma unroll 4
    for (int32_t i0 = 0; i0 &lt; ((A1_dimension + 31) / 32); i0++) {
        for (int32_t i1 = 0; i1 &lt; 32; i1++) {
            int32_t i = i0 * 32 + i1;
            for (int32_t jA = A2_pos[i]; jA &lt; A2_pos[(i + 1)]; jA++) {
                int32_t j = A2_crd[jA];
                y_vals[i] = y_vals[i] + A_vals[jA] * x_vals[j];
            }
        }
    }
}</code></pre></p>
<h2 id="parallelize-command">Parallelize Command</h2>
<p>The <code>parallelize(i, parallel_unit, output_race_strategy)</code> transformation tags
an index variable <code>i</code> for parallel execution on hardware type <code>parallel_unit</code>.
Data races are handled by an <code>output_race_strategy</code>. Since the other
transformations expect serial code, <code>parallelize</code> must come last in a series of
transformations. </p>
<p>For the SpMV example, we could have
<pre class="highlight"><code class="language-c++">stmt = stmt.parallelize(i, ParallelUnit::CPUThread, OutputRaceStrategy::NoRaces);</code></pre>
<pre class="highlight"><code class="language-c">#pragma omp parallel for schedule(runtime)
for (int32_t i = 0; i &lt; A1_dimension; i++) {
    for (int32_t jA = A2_pos[i]; jA &lt; A2_pos[(i + 1)]; jA++) {
        int32_t j = A2_crd[jA];
        y_vals[i] = y_vals[i] + A_vals[jA] * x_vals[j];
    }
}</code></pre></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="computations.html" class="btn btn-neutral float-left" title="Computing on Tensors"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="pytensors.html" class="btn btn-neutral float-right" title="Defining Tensors">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="computations.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="pytensors.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '.';</script>
    <script src="js/theme_extra.js" defer></script>
    <script src="js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
