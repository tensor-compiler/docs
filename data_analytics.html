<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="favicon.ico" />
    <title>Data Analytics: MTTKRP - TACO Documentation</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Data Analytics: MTTKRP";
        var mkdocs_page_input_path = "data_analytics.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> TACO Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">C++ API</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="tensors.html">Defining Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="computations.html">Computing on Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="scheduling.html">Providing a Schedule</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Python API</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="pytensors.html">Defining Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="pycomputations.html">Computing on Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="http://tensor-compiler.org/reference/">Reference Manual</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Example Applications</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="scientific_computing.html">Scientific Computing: SpMV</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="data_analytics.html">Data Analytics: MTTKRP</a>
    <ul class="current">
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="machine_learning.html">Machine Learning: SDDMM</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Advanced Usage</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="optimization.html">Strategies for Optimization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Guide to Benchmarking</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="controlling_memory.html">Controlling Memory</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">TACO Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Example Applications &raquo;</li>
      <li>Data Analytics: MTTKRP</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="data-analytics-mttkrp">Data Analytics: MTTKRP</h1>
<p>Matricized tensor times Khatri-Rao product (MTTKRP) is a bottleneck operation
in various algorithms - such as Alternating Least Squares - for computing
sparse tensor factorizations like the Canonical Polyadic Decomposition.
Mathematically, mode-1 MTTKRP (for three-dimensional tensors) can be expressed 
as </p>
<p>
<script type="math/tex; mode=display">A = B_{(1)} (D \odot C),</script>
</p>
<p>where <script type="math/tex">A</script>, <script type="math/tex">C</script>, and <script type="math/tex">D</script> are typically dense matrices, <script type="math/tex">B</script> is a
three-dimensional tensor (matricizied along the first mode), and <script type="math/tex">\odot</script>
denotes the Khatri-Rao product. This operation can also be expressed in <a href="pycomputations.html#specifying-tensor-algebra-computations">index
notation</a> as </p>
<p>
<script type="math/tex; mode=display">A_{ij} = B_{ikl} \cdot D_{lj} \cdot C_{kj}.</script>
</p>
<p>You can use the TACO C++ API to easily and efficiently compute the MTTKRP, as
shown here:
<pre class="highlight"><code class="language-c++">// On Linux and MacOS, you can compile and run this program like so:
//   g++ -std=c++11 -O3 -DNDEBUG -DTACO -I ../../include -L../../build/lib mttkrp.cpp -o mttkrp -ltaco
//   LD_LIBRARY_PATH=../../build/lib ./mttkrp
#include &lt;random&gt;
#include "taco.h"
using namespace taco;
int main(int argc, char* argv[]) {
  std::default_random_engine gen(0);
  std::uniform_real_distribution&lt;double&gt; unif(0.0, 1.0);
  // Predeclare the storage formats that the inputs and output will be stored as.
  // To define a format, you must specify whether each dimension is dense or 
  // sparse and (optionally) the order in which dimensions should be stored. The 
  // formats declared below correspond to compressed sparse fiber (csf) and 
  // row-major dense (rm).
  Format csf({Sparse,Sparse,Sparse});
  Format  rm({Dense,Dense});

  // Load a sparse order-3 tensor from file (stored in the FROSTT format) and 
  // store it as a compressed sparse fiber tensor. The tensor in this example 
  // can be download from: http://frostt.io/tensors/nell-2/
  Tensor&lt;double&gt; B = read("nell-2.tns", csf);
  // Generate a random dense matrix and store it in row-major (dense) format. 
  // Matrices correspond to order-2 tensors in taco.
  Tensor&lt;double&gt; C({B.getDimension(1), 25}, rm);
  for (int i = 0; i &lt; C.getDimension(0); ++i) {
    for (int j = 0; j &lt; C.getDimension(1); ++j) {
      C.insert({i,j}, unif(gen));
    }
  }
  C.pack();


  // Generate another random dense matrix and store it in row-major format.
  Tensor&lt;double&gt; D({B.getDimension(2), 25}, rm);
  for (int i = 0; i &lt; D.getDimension(0); ++i) {
    for (int j = 0; j &lt; D.getDimension(1); ++j) {
      D.insert({i,j}, unif(gen));
    }
  }
  D.pack();

  // Declare the output matrix to be a dense matrix with 25 columns and the same
  // number of rows as the number of slices along the first dimension of input
  // tensor B, to be also stored as a row-major dense matrix.
  Tensor&lt;double&gt; A({B.getDimension(0), 25}, rm);


  // Define the MTTKRP computation using index notation.
  IndexVar i, j, k, l;
  A(i,j) = B(i,k,l) * D(l,j) * C(k,j);
  // At this point, we have defined how entries in the output matrix should be
  // computed from entries in the input tensor and matrices but have not actually
  // performed the computation yet. To do so, we must first tell taco to generate
  // code that can be executed to compute the MTTKRP operation.
  A.compile();
  // We can now call the functions taco generated to assemble the indices of the
  // output matrix and then actually compute the MTTKRP.
  A.assemble();
  A.compute();
  // Write the output of the computation to file (stored in the FROSTT format).
  write("A.tns", A);
}</code></pre></p>
<p>You can also use the TACO Python API to perform the same computation, as
demonstrated here:</p>
<pre class="highlight"><code class="language-python">import pytaco as pt
import numpy as np
from pytaco import compressed, dense

# Define formats for storing the sparse tensor and dense matrices
csf = pt.format([compressed, compressed, compressed])
rm  = pt.format([dense, dense])

# Load a sparse three-dimensional tensor from file (stored in the FROSTT
# format) and store it as a compressed sparse fiber tensor. The tensor in this
# example can be download from: http://frostt.io/tensors/nell-2/
B = pt.read("nell-2.tns", csf);

# Generate two random matrices using NumPy and pass them into TACO
C = pt.from_array(np.random.uniform(size=(B.shape[1], 25)))
D = pt.from_array(np.random.uniform(size=(B.shape[2], 25)))

# Declare the result to be a dense matrix
A = pt.tensor([B.shape[0], 25], rm)

# Declare index vars
i, j, k, l = get_index_vars(4)

# Define the MTTKRP computation
A[i, j] = B[i, k, l] * D[l, j] * C[k, j]

# Perform the MTTKRP computation and write the result to file
pt.write("A.tns", A)</code></pre>
<p>When you run the above Python program, TACO will generate code under the hood
that efficiently performs the computation in one shot.  This lets TACO avoid
materializing the intermediate Khatri-Rao product, thus reducing the amount of
memory accesses and speeding up the computation.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="scientific_computing.html" class="btn btn-neutral float-left" title="Scientific Computing: SpMV"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="machine_learning.html" class="btn btn-neutral float-right" title="Machine Learning: SDDMM">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="scientific_computing.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="machine_learning.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '.';</script>
    <script src="js/theme_extra.js" defer></script>
    <script src="js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
