<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="favicon.ico" />
    <title>Guide to Benchmarking - TACO Documentation</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Guide to Benchmarking";
        var mkdocs_page_input_path = "benchmarking.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> TACO Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">C++ API</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="tensors.html">Defining Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="computations.html">Computing on Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="scheduling.html">Providing a Schedule</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Python API</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="pytensors.html">Defining Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="pycomputations.html">Computing on Tensors</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="http://tensor-compiler.org/reference/">Reference Manual</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Example Applications</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="scientific_computing.html">Scientific Computing: SpMV</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="data_analytics.html">Data Analytics: MTTKRP</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="machine_learning.html">Machine Learning: SDDMM</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Advanced Usage</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="optimization.html">Strategies for Optimization</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="benchmarking.html">Guide to Benchmarking</a>
    <ul class="current">
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="controlling_memory.html">Controlling Memory</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">TACO Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Advanced Usage &raquo;</li>
      <li>Guide to Benchmarking</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="guide-to-benchmarking">Guide to Benchmarking</h1>
<p>The performance of Python applications that use TACO can be measured using
Python's built-in <code>time.perf_counter</code> function with minimal changes to the
applications.  As an example, we can benchmark the performance of the
scientific computing application shown <a href="scientific_computing.html">here</a> as
follows:</p>
<pre class="highlight"><code class="language-python">import pytaco as pt
from pytaco import compressed, dense
import numpy as np
import time

csr = pt.format([dense, compressed])
dv  = pt.format([dense])

A = pt.read("pwtk.mtx", csr)
x = pt.from_array(np.random.uniform(size=A.shape[1]))
z = pt.from_array(np.random.uniform(size=A.shape[0]))
y = pt.tensor([A.shape[0]], dv)

i, j = pt.get_index_vars(2)
y[i] = A[i, j] * x[j] + z[i]

# Tell TACO to generate code to perform the SpMV computation
y.compile()

# Benchmark the actual SpMV computation
start = time.perf_counter()
y.compute()
end = time.perf_counter()

print("Execution time: {0} seconds".format(end - start))</code></pre>
<p>In order to accurately measure TACO's computational performance, <strong>only the
time it takes to actually perform a computation should be measured.  The time
it takes to generate code under the hood for performing that computation should
not be measured</strong>, since this overhead can be quite variable but can often be
amortized in practice.  By default though, TACO will only generate and compile
code it needs for performing a computation immediately before it has to
actually perform the computation.  As the example above demonstrates, by
manually calling the result tensor's <code>compile</code> method, we can tell TACO to
generate code needed for performing the computation before benchmarking starts,
letting us measure only the performance of the computation itself.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code>pytaco.evaluate</code> and <code>pytaco.einsum</code> should not be used to benchmark
TACO's computational performance, since timing those functions will
include the time it takes to generate code for performing the computation.</p>
</div>
<p><strong>The time it takes to construct the initial operand tensors should also not be
measured</strong>, since again this overhead can often be amortized in practice.  By
default, <code>pytaco.read</code> and functions for converting NumPy arrays and SciPy
matrices to TACO tensors return fully constructed tensors.  If you add nonzero
elements to an operand tensor by invoking its <code>insert</code> method though, then
<code>pack</code> must also be explicitly invoked before any benchmarking is done:</p>
<pre class="highlight"><code class="language-python">import pytaco as pt
from pytaco import compressed, dense
import numpy as np
import random
import time

csr = pt.format([dense, compressed])
dv  = pt.format([dense])

A = pt.read("pwtk.mtx", csr)
x = pt.tensor([A.shape[1]], dv)
z = pt.tensor([A.shape[0]], dv)
y = pt.tensor([A.shape[0]], dv)

# Insert random values into x and z and pack them into dense arrays
for k in range(A.shape[1]):
  x.insert([k], random.random())
x.pack()
for k in range(A.shape[0]):
  z.insert([k], random.random())
z.pack()

i, j = pt.get_index_vars(2)
y[i] = A[i, j] * x[j] + z[i]

y.compile()

start = time.perf_counter()
y.compute()
end = time.perf_counter()

print("Execution time: {0} seconds".format(end - start))</code></pre>
<p>TACO avoids regenerating code for performing the same computation though as
long as the computation is redefined with the same index variables and with the
same operand and result tensors.  Thus, if your application executes the same
computation many times in a loop and if the computation is executed on
sufficiently large data sets, TACO will naturally amortize the overhead
associated with generating code for performing the computation.  In such 
scenarios, it is acceptable to include the initial code generation overhead 
in the performance measurement:</p>
<pre class="highlight"><code class="language-python">import pytaco as pt
from pytaco import compressed, dense
import numpy as np
import time

csr = pt.format([dense, compressed])
dv  = pt.format([dense])

A = pt.read("pwtk.mtx", csr)
x = pt.tensor([A.shape[1]], dv)
z = pt.tensor([A.shape[0]], dv)
y = pt.tensor([A.shape[0]], dv)

for k in range(A.shape[1]):
  x.insert([k], random.random())
x.pack()
for k in range(A.shape[0]):
  z.insert([k], random.random())
z.pack()

i, j = pt.get_index_vars(2)

# Benchmark the iterative SpMV computation, including overhead for 
# generating code in the first iteration to perform the computation
start = time.perf_counter()
for k in range(1000):
  y[i] = A[i, j] * x[j] + z[i]
  y.evaluate()
  x[i] = y[i]
  x.evaluate()
end = time.perf_counter()

print("Execution time: {0} seconds".format(end - start))</code></pre>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In order to avoid regenerating code for performing a computation, the
computation must be redefined with the exact same index variable <em>objects</em>
and also with the exact same tensor objects for operands and result.  In
the example above, every loop iteration redefines the computation of <code>y</code>
and <code>x</code> using the same tensor and index variable objects costructed outside
the loop, so TACO will only generate code to compute <code>y</code> and <code>x</code> in the
first iteration.  If the index variables were constructed inside the loop
though, TACO would regenerate code to compute <code>y</code> and <code>x</code> in every loop
iteration, and the compilation overhead would not be amortized. </p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As a rough rule of thumb, if a computation takes on the order of seconds or
more in total to perform across all invocations with identical operands and
result (and is always redefined with identical index variables), then it is
acceptable to include the overhead associated with generating code for
performing the computation in performance measurements.</p>
</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="optimization.html" class="btn btn-neutral float-left" title="Strategies for Optimization"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="controlling_memory.html" class="btn btn-neutral float-right" title="Controlling Memory">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="optimization.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="controlling_memory.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '.';</script>
    <script src="js/theme_extra.js" defer></script>
    <script src="js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
